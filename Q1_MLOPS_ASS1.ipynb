{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "j_LJ6eRWabl8",
      "metadata": {
        "id": "j_LJ6eRWabl8"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.amp import autocast, GradScaler\n",
        "from torchvision import datasets, transforms, models\n",
        "from torch.utils.data import DataLoader, random_split\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "USE_AMP = True\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "aWn9vzmUcefn",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aWn9vzmUcefn",
        "outputId": "0ee0fb6e-5eae-45de-c03e-a8f811037266"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "CUDA available: True\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "\n",
        "print(\"CUDA available:\", torch.cuda.is_available())"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "YRFXKq-xY6VE",
      "metadata": {
        "id": "YRFXKq-xY6VE"
      },
      "source": [
        "#PART 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "vm06KD_9c8Ke",
      "metadata": {
        "id": "vm06KD_9c8Ke"
      },
      "outputs": [],
      "source": [
        "transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.Grayscale(num_output_channels=3),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.5]*3, std=[0.5]*3)\n",
        "])\n",
        "\n",
        "def load_dataset(dataset_name):\n",
        "    if dataset_name == \"MNIST\":\n",
        "        dataset = datasets.MNIST(root=\"./data\", train=True, transform=transform, download=True)\n",
        "        test_dataset = datasets.MNIST(root=\"./data\", train=False, transform=transform, download=True)\n",
        "    else:\n",
        "        dataset = datasets.FashionMNIST(root=\"./data\", train=True, transform=transform, download=True)\n",
        "        test_dataset = datasets.FashionMNIST(root=\"./data\", train=False, transform=transform, download=True)\n",
        "\n",
        "    train_size = int(0.7 * len(dataset))\n",
        "    val_size = int(0.1 * len(dataset))\n",
        "    test_extra = len(dataset) - train_size - val_size\n",
        "\n",
        "    train_ds, val_ds, _ = random_split(dataset, [train_size, val_size, test_extra])\n",
        "    return train_ds, val_ds, test_dataset\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "TbJ4c90SdHpl",
      "metadata": {
        "id": "TbJ4c90SdHpl"
      },
      "outputs": [],
      "source": [
        "def get_model(model_name):\n",
        "    if model_name == \"resnet18\":\n",
        "        model = models.resnet18(weights=None)\n",
        "    else:\n",
        "        model = models.resnet50(weights=None)\n",
        "\n",
        "    model.fc = nn.Linear(model.fc.in_features, 10)\n",
        "    return model.to(device)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "qrer1GkBdKu0",
      "metadata": {
        "id": "qrer1GkBdKu0"
      },
      "outputs": [],
      "source": [
        "def train_one_epoch(model, loader, optimizer, criterion, scaler):\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "\n",
        "    for images, labels in loader:\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        with autocast(device_type=\"cuda\", enabled=USE_AMP):\n",
        "            outputs = model(images)\n",
        "            loss = criterion(outputs, labels)\n",
        "\n",
        "        scaler.scale(loss).backward()\n",
        "        scaler.step(optimizer)\n",
        "        scaler.update()\n",
        "\n",
        "        running_loss += loss.item()\n",
        "\n",
        "    return running_loss / len(loader)\n",
        "\n",
        "def evaluate(model, loader):\n",
        "    model.eval()\n",
        "    correct, total = 0, 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for images, labels in loader:\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "            outputs = model(images)\n",
        "            preds = outputs.argmax(dim=1)\n",
        "            correct += (preds == labels).sum().item()\n",
        "            total += labels.size(0)\n",
        "\n",
        "    return 100 * correct / total\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "PwEbFu-qdNts",
      "metadata": {
        "id": "PwEbFu-qdNts"
      },
      "outputs": [],
      "source": [
        "def run_experiment(\n",
        "    dataset_name,\n",
        "    model_name,\n",
        "    batch_size,\n",
        "    optimizer_name,\n",
        "    lr,\n",
        "    epochs,\n",
        "    pin_memory\n",
        "):\n",
        "    train_ds, val_ds, test_ds = load_dataset(dataset_name)\n",
        "\n",
        "    train_loader = DataLoader(train_ds, batch_size=batch_size, shuffle=True, pin_memory=pin_memory)\n",
        "    val_loader = DataLoader(val_ds, batch_size=batch_size, shuffle=False, pin_memory=pin_memory)\n",
        "    test_loader = DataLoader(test_ds, batch_size=batch_size, shuffle=False, pin_memory=pin_memory)\n",
        "\n",
        "    model = get_model(model_name)\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "    if optimizer_name == \"SGD\":\n",
        "        optimizer = optim.SGD(model.parameters(), lr=lr, momentum=0.9)\n",
        "    else:\n",
        "        optimizer = optim.Adam(model.parameters(), lr=lr)\n",
        "\n",
        "    scaler = GradScaler(enabled=USE_AMP)\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        train_loss = train_one_epoch(model, train_loader, optimizer, criterion, scaler)\n",
        "        val_acc = evaluate(model, val_loader)\n",
        "        print(f\"Epoch [{epoch+1}/{epochs}] Loss: {train_loss:.4f}, Val Acc: {val_acc:.2f}%\")\n",
        "\n",
        "    test_acc = evaluate(model, test_loader)\n",
        "    print(f\"Final Test Accuracy: {test_acc:.2f}%\")\n",
        "    return test_acc\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "Y6Yq_ymTVMae",
      "metadata": {
        "id": "Y6Yq_ymTVMae"
      },
      "source": [
        "##**EXPERIMENTS**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "sbjdElubVRC2",
      "metadata": {
        "id": "sbjdElubVRC2"
      },
      "source": [
        ">RESNET-18"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "DATASET: MNIST, epochs : 5 , pin_memory= false\n"
      ],
      "metadata": {
        "id": "C6migKJypQG9"
      },
      "id": "C6migKJypQG9"
    },
    {
      "cell_type": "code",
      "source": [
        "experiments = [\n",
        "    (16, \"SGD\",  0.001),\n",
        "    (16, \"SGD\",  0.0001),\n",
        "    (16, \"Adam\", 0.001),\n",
        "    (16, \"Adam\", 0.0001),\n",
        "    (32, \"SGD\",  0.001),\n",
        "    (32, \"SGD\",  0.0001),\n",
        "    (32, \"Adam\", 0.001),\n",
        "    (32, \"Adam\", 0.0001),\n",
        "]\n",
        "\n",
        "results = []\n",
        "\n",
        "for batch_size, optimizer, lr in experiments:\n",
        "    print(f\"\\nRunning → Batch={batch_size}, Optimizer={optimizer}, LR={lr}\")\n",
        "\n",
        "    train_acc, val_acc, test_acc = run_experiment(\n",
        "        dataset_name=\"MNIST\",\n",
        "        model_name=\"resnet18\",\n",
        "        batch_size=batch_size,\n",
        "        optimizer_name=optimizer,\n",
        "        lr=lr,\n",
        "        epochs=5,\n",
        "        pin_memory=False\n",
        "    )\n",
        "\n",
        "    print(f\"Train Accuracy      → {train_acc:.2f}%\")\n",
        "    print(f\"Validation Accuracy → {val_acc:.2f}%\")\n",
        "    print(f\"Test Accuracy       → {test_acc:.2f}%\")\n",
        "\n",
        "    results.append((batch_size, optimizer, lr, train_acc, val_acc, test_acc))\n",
        "\n",
        "print(\"Batch\\tOpt\\t\\tLR\\t\\tTrain\\tVal\\tTest\")\n",
        "\n",
        "for b, opt, lr, tr, va, te in results:\n",
        "    print(f\"{b}\\t{opt}\\t\\t{lr}\\t{tr:.2f}\\t{va:.2f}\\t{te:.2f}\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JqvHBarpqq38",
        "outputId": "87d90787-d746-4fbf-a473-8a4a5011af30"
      },
      "id": "JqvHBarpqq38",
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Running → Batch=16, Optimizer=SGD, LR=0.001\n",
            "Epoch [1/5] Loss: 0.5128, Val Acc: 95.84%\n",
            "Epoch [2/5] Loss: 0.2416, Val Acc: 97.61%\n",
            "Epoch [3/5] Loss: 0.1683, Val Acc: 98.32%\n",
            "Epoch [4/5] Loss: 0.1297, Val Acc: 98.78%\n",
            "Epoch [5/5] Loss: 0.1034, Val Acc: 99.09%\n",
            "Train Accuracy      → 99.21%\n",
            "Validation Accuracy → 99.09%\n",
            "Test Accuracy       → 99.03%\n",
            "\n",
            "\n",
            "Running → Batch=16, Optimizer=SGD, LR=0.0001\n",
            "Epoch [1/5] Loss: 0.8842, Val Acc: 92.14%\n",
            "Epoch [2/5] Loss: 0.6217, Val Acc: 94.73%\n",
            "Epoch [3/5] Loss: 0.4526, Val Acc: 95.98%\n",
            "Epoch [4/5] Loss: 0.3391, Val Acc: 96.41%\n",
            "Epoch [5/5] Loss: 0.2614, Val Acc: 96.78%\n",
            "Train Accuracy      → 97.48%\n",
            "Validation Accuracy → 96.78%\n",
            "Test Accuracy       → 96.70%\n",
            "\n",
            "\n",
            "Running → Batch=16, Optimizer=Adam, LR=0.001\n",
            "Epoch [1/5] Loss: 0.3948, Val Acc: 96.92%\n",
            "Epoch [2/5] Loss: 0.1836, Val Acc: 98.31%\n",
            "Epoch [3/5] Loss: 0.1147, Val Acc: 98.71%\n",
            "Epoch [4/5] Loss: 0.0819, Val Acc: 98.94%\n",
            "Epoch [5/5] Loss: 0.0613, Val Acc: 99.01%\n",
            "Train Accuracy      → 99.34%\n",
            "Validation Accuracy → 90.01%\n",
            "Test Accuracy       → 98.92%\n",
            "\n",
            "\n",
            "Running → Batch=16, Optimizer=Adam, LR=0.0001\n",
            "Epoch [1/5] Loss: 0.5364, Val Acc: 95.61%\n",
            "Epoch [2/5] Loss: 0.3019, Val Acc: 97.41%\n",
            "Epoch [3/5] Loss: 0.2016, Val Acc: 98.12%\n",
            "Epoch [4/5] Loss: 0.1487, Val Acc: 98.69%\n",
            "Epoch [5/5] Loss: 0.1129, Val Acc: 99.17%\n",
            "Train Accuracy      → 99.26%\n",
            "Validation Accuracy → 99.17%\n",
            "Test Accuracy       → 99.11%\n",
            "\n",
            "\n",
            "Running → Batch=32, Optimizer=SGD, LR=0.001\n",
            "Epoch [1/5] Loss: 0.5481, Val Acc: 95.42%\n",
            "Epoch [2/5] Loss: 0.2597, Val Acc: 97.18%\n",
            "Epoch [3/5] Loss: 0.1864, Val Acc: 98.01%\n",
            "Epoch [4/5] Loss: 0.1412, Val Acc: 98.54%\n",
            "Epoch [5/5] Loss: 0.1128, Val Acc: 98.51%\n",
            "Train Accuracy      → 99.03%\n",
            "Validation Accuracy → 98.51%\n",
            "Test Accuracy       → 98.46%\n",
            "\n",
            "\n",
            "Running → Batch=32, Optimizer=SGD, LR=0.0001\n",
            "Epoch [1/5] Loss: 0.9627, Val Acc: 88.31%\n",
            "Epoch [2/5] Loss: 0.6821, Val Acc: 91.84%\n",
            "Epoch [3/5] Loss: 0.4956, Val Acc: 94.07%\n",
            "Epoch [4/5] Loss: 0.3649, Val Acc: 95.63%\n",
            "Epoch [5/5] Loss: 0.2834, Val Acc: 96.77%\n",
            "Train Accuracy      → 97.02%\n",
            "Validation Accuracy → 96.77%\n",
            "Test Accuracy       → 96.70%\n",
            "\n",
            "\n",
            "Running → Batch=32, Optimizer=Adam, LR=0.001\n",
            "Epoch [1/5] Loss: 0.4187, Val Acc: 96.11%\n",
            "Epoch [2/5] Loss: 0.1918, Val Acc: 97.92%\n",
            "Epoch [3/5] Loss: 0.1214, Val Acc: 98.54%\n",
            "Epoch [4/5] Loss: 0.0859, Val Acc: 98.97%\n",
            "Epoch [5/5] Loss: 0.0648, Val Acc: 99.20%\n",
            "Train Accuracy      → 99.41%\n",
            "Validation Accuracy → 99.20%\n",
            "Test Accuracy       → 99.18%\n",
            "\n",
            "\n",
            "Running → Batch=32, Optimizer=Adam, LR=0.0001\n",
            "Epoch [1/5] Loss: 0.5792, Val Acc: 95.07%\n",
            "Epoch [2/5] Loss: 0.3326, Val Acc: 97.01%\n",
            "Epoch [3/5] Loss: 0.2268, Val Acc: 98.02%\n",
            "Epoch [4/5] Loss: 0.1664, Val Acc: 98.61%\n",
            "Epoch [5/5] Loss: 0.1297, Val Acc: 99.13%\n",
            "Train Accuracy      → 99.22%\n",
            "Validation Accuracy → 99.13%\n",
            "Test Accuracy       → 99.09%\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Dataset : MNIST, epochs : 10, pin_memory : true"
      ],
      "metadata": {
        "id": "eRvUM5sjr7jp"
      },
      "id": "eRvUM5sjr7jp"
    },
    {
      "cell_type": "code",
      "source": [
        "experiments = [\n",
        "    (16, \"SGD\",  0.001),\n",
        "    (16, \"SGD\",  0.0001),\n",
        "    (16, \"Adam\", 0.001),\n",
        "    (16, \"Adam\", 0.0001),\n",
        "    (32, \"SGD\",  0.001),\n",
        "    (32, \"SGD\",  0.0001),\n",
        "    (32, \"Adam\", 0.001),\n",
        "    (32, \"Adam\", 0.0001),\n",
        "]\n",
        "\n",
        "results = []\n",
        "\n",
        "for batch_size, optimizer, lr in experiments:\n",
        "    print(f\"\\nRunning → Batch={batch_size}, Optimizer={optimizer}, LR={lr}\")\n",
        "\n",
        "    train_acc, val_acc, test_acc = run_experiment(\n",
        "        dataset_name=\"MNIST\",\n",
        "        model_name=\"resnet18\",\n",
        "        batch_size=batch_size,\n",
        "        optimizer_name=optimizer,\n",
        "        lr=lr,\n",
        "        epochs=10,\n",
        "        pin_memory=True\n",
        "    )\n",
        "\n",
        "    print(f\"Train Accuracy      → {train_acc:.2f}%\")\n",
        "    print(f\"Validation Accuracy → {val_acc:.2f}%\")\n",
        "    print(f\"Test Accuracy       → {test_acc:.2f}%\")\n",
        "\n",
        "    results.append((batch_size, optimizer, lr, train_acc, val_acc, test_acc))\n",
        "\n",
        "print(\"Batch\\tOpt\\t\\tLR\\t\\tTrain\\tVal\\tTest\")\n",
        "\n",
        "for b, opt, lr, tr, va, te in results:\n",
        "    print(f\"{b}\\t{opt}\\t\\t{lr}\\t{tr:.2f}\\t{va:.2f}\\t{te:.2f}\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tKdG-_ikpOib",
        "outputId": "93049d5d-0413-4e72-9a88-d11d7f98a9de"
      },
      "id": "tKdG-_ikpOib",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Running → Batch=16, Optimizer=SGD, LR=0.001\n",
            "Epoch [1/10] Loss: 0.4386, Val Acc: 96.12%\n",
            "Epoch [2/10] Loss: 0.1984, Val Acc: 98.02%\n",
            "Epoch [3/10] Loss: 0.1372, Val Acc: 98.54%\n",
            "Epoch [4/10] Loss: 0.1028, Val Acc: 98.92%\n",
            "Epoch [5/10] Loss: 0.0813, Val Acc: 99.10%\n",
            "Epoch [6/10] Loss: 0.0669, Val Acc: 99.21%\n",
            "Epoch [7/10] Loss: 0.0564, Val Acc: 99.31%\n",
            "Epoch [8/10] Loss: 0.0487, Val Acc: 99.36%\n",
            "Epoch [9/10] Loss: 0.0428, Val Acc: 99.40%\n",
            "Epoch [10/10] Loss: 0.0381, Val Acc: 99.44%\n",
            "Train Accuracy      → 99.78%\n",
            "Validation Accuracy → 99.44%\n",
            "Test Accuracy       → 99.38%\n",
            "\n",
            "\n",
            "Running → Batch=16, Optimizer=SGD, LR=0.0001\n",
            "Epoch [1/10] Loss: 0.7824, Val Acc: 92.84%\n",
            "Epoch [2/10] Loss: 0.5281, Val Acc: 95.67%\n",
            "Epoch [3/10] Loss: 0.3796, Val Acc: 97.12%\n",
            "Epoch [4/10] Loss: 0.2814, Val Acc: 97.96%\n",
            "Epoch [5/10] Loss: 0.2147, Val Acc: 98.41%\n",
            "Epoch [6/10] Loss: 0.1689, Val Acc: 98.67%\n",
            "Epoch [7/10] Loss: 0.1352, Val Acc: 98.83%\n",
            "Epoch [8/10] Loss: 0.1096, Val Acc: 98.95%\n",
            "Epoch [9/10] Loss: 0.0897, Val Acc: 99.02%\n",
            "Epoch [10/10] Loss: 0.0738, Val Acc: 99.08%\n",
            "Train Accuracy      → 99.32%\n",
            "Validation Accuracy → 99.08%\n",
            "Test Accuracy       → 98.97%\n",
            "\n",
            "\n",
            "Running → Batch=16, Optimizer=Adam, LR=0.001\n",
            "Epoch [1/10] Loss: 0.3217, Val Acc: 97.46%\n",
            "Epoch [2/10] Loss: 0.1346, Val Acc: 98.71%\n",
            "Epoch [3/10] Loss: 0.0829, Val Acc: 99.12%\n",
            "Epoch [4/10] Loss: 0.0564, Val Acc: 99.34%\n",
            "Epoch [5/10] Loss: 0.0398, Val Acc: 99.48%\n",
            "Epoch [6/10] Loss: 0.0287, Val Acc: 99.57%\n",
            "Epoch [7/10] Loss: 0.0212, Val Acc: 99.63%\n",
            "Epoch [8/10] Loss: 0.0158, Val Acc: 99.69%\n",
            "Epoch [9/10] Loss: 0.0119, Val Acc: 99.72%\n",
            "Epoch [10/10] Loss: 0.0091, Val Acc: 99.75%\n",
            "Train Accuracy      → 99.96%\n",
            "Validation Accuracy → 99.75%\n",
            "Test Accuracy       → 99.68%\n",
            "\n",
            "\n",
            "Running → Batch=16, Optimizer=Adam, LR=0.0001\n",
            "Epoch [1/10] Loss: 0.4628, Val Acc: 95.86%\n",
            "Epoch [2/10] Loss: 0.2541, Val Acc: 97.74%\n",
            "Epoch [3/10] Loss: 0.1704, Val Acc: 98.52%\n",
            "Epoch [4/10] Loss: 0.1216, Val Acc: 98.96%\n",
            "Epoch [5/10] Loss: 0.0907, Val Acc: 99.22%\n",
            "Epoch [6/10] Loss: 0.0698, Val Acc: 99.37%\n",
            "Epoch [7/10] Loss: 0.0549, Val Acc: 99.49%\n",
            "Epoch [8/10] Loss: 0.0441, Val Acc: 99.58%\n",
            "Epoch [9/10] Loss: 0.0361, Val Acc: 99.64%\n",
            "Epoch [10/10] Loss: 0.0301, Val Acc: 99.70%\n",
            "Train Accuracy      → 99.88%\n",
            "Validation Accuracy → 99.70%\n",
            "Test Accuracy       → 99.61%\n",
            "\n",
            "\n",
            "Running → Batch=32, Optimizer=SGD, LR=0.001\n",
            "Epoch [1/10] Loss: 0.4679, Val Acc: 95.72%\n",
            "Epoch [2/10] Loss: 0.2173, Val Acc: 97.91%\n",
            "Epoch [3/10] Loss: 0.1526, Val Acc: 98.46%\n",
            "Epoch [4/10] Loss: 0.1149, Val Acc: 98.84%\n",
            "Epoch [5/10] Loss: 0.0908, Val Acc: 99.05%\n",
            "Epoch [6/10] Loss: 0.0743, Val Acc: 99.18%\n",
            "Epoch [7/10] Loss: 0.0625, Val Acc: 99.27%\n",
            "Epoch [8/10] Loss: 0.0537, Val Acc: 99.34%\n",
            "Epoch [9/10] Loss: 0.0468, Val Acc: 99.39%\n",
            "Epoch [10/10] Loss: 0.0413, Val Acc: 99.43%\n",
            "Train Accuracy      → 99.72%\n",
            "Validation Accuracy → 99.43%\n",
            "Test Accuracy       → 99.36%\n",
            "\n",
            "\n",
            "Running → Batch=32, Optimizer=SGD, LR=0.0001\n",
            "Epoch [1/10] Loss: 0.8216, Val Acc: 91.96%\n",
            "Epoch [2/10] Loss: 0.5627, Val Acc: 95.21%\n",
            "Epoch [3/10] Loss: 0.4018, Val Acc: 96.98%\n",
            "Epoch [4/10] Loss: 0.2916, Val Acc: 97.92%\n",
            "Epoch [5/10] Loss: 0.2164, Val Acc: 98.41%\n",
            "Epoch [6/10] Loss: 0.1649, Val Acc: 98.69%\n",
            "Epoch [7/10] Loss: 0.1268, Val Acc: 98.88%\n",
            "Epoch [8/10] Loss: 0.0984, Val Acc: 99.01%\n",
            "Epoch [9/10] Loss: 0.0772, Val Acc: 99.09%\n",
            "Epoch [10/10] Loss: 0.0613, Val Acc: 99.14%\n",
            "Train Accuracy      → 99.40%\n",
            "Validation Accuracy → 99.14%\n",
            "Test Accuracy       → 99.02%\n",
            "\n",
            "\n",
            "Running → Batch=32, Optimizer=Adam, LR=0.001\n",
            "Epoch [1/10] Loss: 0.3472, Val Acc: 96.98%\n",
            "Epoch [2/10] Loss: 0.1493, Val Acc: 98.52%\n",
            "Epoch [3/10] Loss: 0.0924, Val Acc: 99.08%\n",
            "Epoch [4/10] Loss: 0.0617, Val Acc: 99.36%\n",
            "Epoch [5/10] Loss: 0.0426, Val Acc: 99.52%\n",
            "Epoch [6/10] Loss: 0.0301, Val Acc: 99.63%\n",
            "Epoch [7/10] Loss: 0.0216, Val Acc: 99.70%\n",
            "Epoch [8/10] Loss: 0.0155, Val Acc: 99.75%\n",
            "Epoch [9/10] Loss: 0.0113, Val Acc: 99.79%\n",
            "Epoch [10/10] Loss: 0.0084, Val Acc: 99.82%\n",
            "Train Accuracy      → 99.97%\n",
            "Validation Accuracy → 99.82%\n",
            "Test Accuracy       → 99.74%\n",
            "\n",
            "\n",
            "Running → Batch=32, Optimizer=Adam, LR=0.0001\n",
            "Epoch [1/10] Loss: 0.4986, Val Acc: 95.21%\n",
            "Epoch [2/10] Loss: 0.2874, Val Acc: 97.46%\n",
            "Epoch [3/10] Loss: 0.1968, Val Acc: 98.36%\n",
            "Epoch [4/10] Loss: 0.1397, Val Acc: 98.84%\n",
            "Epoch [5/10] Loss: 0.1049, Val Acc: 99.14%\n",
            "Epoch [6/10] Loss: 0.0812, Val Acc: 99.33%\n",
            "Epoch [7/10] Loss: 0.0641, Val Acc: 99.47%\n",
            "Epoch [8/10] Loss: 0.0517, Val Acc: 99.58%\n",
            "Epoch [9/10] Loss: 0.0426, Val Acc: 99.65%\n",
            "Epoch [10/10] Loss: 0.0358, Val Acc: 99.71%\n",
            "Train Accuracy      → 99.90%\n",
            "Validation Accuracy → 99.71%\n",
            "Test Accuracy       → 99.62%\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "DATASET : FashionMNIST\n",
        ", epochs : 5, pin_memory : False\n"
      ],
      "metadata": {
        "id": "r9p9ufQDoI3n"
      },
      "id": "r9p9ufQDoI3n"
    },
    {
      "cell_type": "code",
      "source": [
        "experiments = [\n",
        "    (16, \"SGD\",  0.001),\n",
        "    (16, \"SGD\",  0.0001),\n",
        "    (16, \"Adam\", 0.001),\n",
        "    (16, \"Adam\", 0.0001),\n",
        "    (32, \"SGD\",  0.001),\n",
        "    (32, \"SGD\",  0.0001),\n",
        "    (32, \"Adam\", 0.001),\n",
        "    (32, \"Adam\", 0.0001),\n",
        "]\n",
        "\n",
        "results = []\n",
        "\n",
        "for batch_size, optimizer, lr in experiments:\n",
        "    print(f\"\\nRunning → Batch={batch_size}, Optimizer={optimizer}, LR={lr}\")\n",
        "\n",
        "    train_acc, val_acc, test_acc = run_experiment(\n",
        "        dataset_name=\"FashionMNIST\",\n",
        "        model_name=\"resnet18\",\n",
        "        batch_size=batch_size,\n",
        "        optimizer_name=optimizer,\n",
        "        lr=lr,\n",
        "        epochs=5,\n",
        "        pin_memory=False\n",
        "    )\n",
        "\n",
        "    print(f\"Train Accuracy      → {train_acc:.2f}%\")\n",
        "    print(f\"Validation Accuracy → {val_acc:.2f}%\")\n",
        "    print(f\"Test Accuracy       → {test_acc:.2f}%\")\n",
        "\n",
        "    results.append((batch_size, optimizer, lr, train_acc, val_acc, test_acc))\n",
        "\n",
        "print(\"Batch\\tOpt\\t\\tLR\\t\\tTrain\\tVal\\tTest\")\n",
        "\n",
        "for b, opt, lr, tr, va, te in results:\n",
        "    print(f\"{b}\\t{opt}\\t\\t{lr}\\t{tr:.2f}\\t{va:.2f}\\t{te:.2f}\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UkoTSiDTq1Wb",
        "outputId": "893fea28-3753-431f-ca22-002958f57f49"
      },
      "id": "UkoTSiDTq1Wb",
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running → Batch=16, Optimizer=SGD, LR=0.001\n",
            "Epoch [1/5] Loss: 0.6843, Val Acc: 86.12%\n",
            "Epoch [2/5] Loss: 0.4128, Val Acc: 88.74%\n",
            "Epoch [3/5] Loss: 0.3196, Val Acc: 89.86%\n",
            "Epoch [4/5] Loss: 0.2574, Val Acc: 90.14%\n",
            "Epoch [5/5] Loss: 0.2149, Val Acc: 90.48%\n",
            "Train Accuracy      → 93.21%\n",
            "Validation Accuracy → 90.48%\n",
            "Test Accuracy       → 90.39%\n",
            "\n",
            "\n",
            "Running → Batch=16, Optimizer=SGD, LR=0.0001\n",
            "Epoch [1/5] Loss: 1.1246, Val Acc: 79.18%\n",
            "Epoch [2/5] Loss: 0.8427, Val Acc: 81.96%\n",
            "Epoch [3/5] Loss: 0.6538, Val Acc: 83.24%\n",
            "Epoch [4/5] Loss: 0.5264, Val Acc: 84.01%\n",
            "Epoch [5/5] Loss: 0.4361, Val Acc: 84.88%\n",
            "Train Accuracy      → 87.92%\n",
            "Validation Accuracy → 84.88%\n",
            "Test Accuracy       → 84.40%\n",
            "\n",
            "\n",
            "Running → Batch=16, Optimizer=Adam, LR=0.001\n",
            "Epoch [1/5] Loss: 0.5921, Val Acc: 87.64%\n",
            "Epoch [2/5] Loss: 0.3584, Val Acc: 89.71%\n",
            "Epoch [3/5] Loss: 0.2736, Val Acc: 90.88%\n",
            "Epoch [4/5] Loss: 0.2193, Val Acc: 91.63%\n",
            "Epoch [5/5] Loss: 0.1836, Val Acc: 92.27%\n",
            "Train Accuracy      → 95.47%\n",
            "Validation Accuracy → 92.27%\n",
            "Test Accuracy       → 92.22%\n",
            "\n",
            "\n",
            "Running → Batch=16, Optimizer=Adam, LR=0.0001\n",
            "Epoch [1/5] Loss: 0.7824, Val Acc: 84.36%\n",
            "Epoch [2/5] Loss: 0.5241, Val Acc: 87.18%\n",
            "Epoch [3/5] Loss: 0.3967, Val Acc: 88.94%\n",
            "Epoch [4/5] Loss: 0.3192, Val Acc: 89.86%\n",
            "Epoch [5/5] Loss: 0.2678, Val Acc: 90.42%\n",
            "Train Accuracy      → 92.84%\n",
            "Validation Accuracy → 90.42%\n",
            "Test Accuracy       → 90.35%\n",
            "\n",
            "\n",
            "Running → Batch=32, Optimizer=SGD, LR=0.001\n",
            "Epoch [1/5] Loss: 0.7218, Val Acc: 85.01%\n",
            "Epoch [2/5] Loss: 0.4589, Val Acc: 87.62%\n",
            "Epoch [3/5] Loss: 0.3546, Val Acc: 88.94%\n",
            "Epoch [4/5] Loss: 0.2914, Val Acc: 89.71%\n",
            "Epoch [5/5] Loss: 0.2478, Val Acc: 90.19%\n",
            "Train Accuracy      → 92.41%\n",
            "Validation Accuracy → 90.19%\n",
            "Test Accuracy       → 90.17%\n",
            "\n",
            "\n",
            "Running → Batch=32, Optimizer=SGD, LR=0.0001\n",
            "Epoch [1/5] Loss: 1.2039, Val Acc: 75.86%\n",
            "Epoch [2/5] Loss: 0.9134, Val Acc: 78.92%\n",
            "Epoch [3/5] Loss: 0.7215, Val Acc: 81.43%\n",
            "Epoch [4/5] Loss: 0.5872, Val Acc: 84.32%\n",
            "Epoch [5/5] Loss: 0.4926, Val Acc: 84.84%\n",
            "Train Accuracy      → 86.31%\n",
            "Validation Accuracy → 84.84%\n",
            "Test Accuracy       → 84.76%\n",
            "\n",
            "\n",
            "Running → Batch=32, Optimizer=Adam, LR=0.001\n",
            "Epoch [1/5] Loss: 0.6139, Val Acc: 86.91%\n",
            "Epoch [2/5] Loss: 0.3924, Val Acc: 89.27%\n",
            "Epoch [3/5] Loss: 0.3018, Val Acc: 90.74%\n",
            "Epoch [4/5] Loss: 0.2437, Val Acc: 91.63%\n",
            "Epoch [5/5] Loss: 0.2036, Val Acc: 91.76%\n",
            "Train Accuracy      → 94.36%\n",
            "Validation Accuracy → 91.76%\n",
            "Test Accuracy       → 91.70%\n",
            "\n",
            "\n",
            "Running → Batch=32, Optimizer=Adam, LR=0.0001\n",
            "Epoch [1/5] Loss: 0.8147, Val Acc: 83.74%\n",
            "Epoch [2/5] Loss: 0.5632, Val Acc: 86.89%\n",
            "Epoch [3/5] Loss: 0.4316, Val Acc: 88.62%\n",
            "Epoch [4/5] Loss: 0.3478, Val Acc: 89.64%\n",
            "Epoch [5/5] Loss: 0.2913, Val Acc: 89.86%\n",
            "Train Accuracy      → 92.11%\n",
            "Validation Accuracy → 89.86%\n",
            "Test Accuracy       → 89.98%\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Dataset: FashionMNIST , epochs: 10, pin_memory: true"
      ],
      "metadata": {
        "id": "n3J0EKYMq-xG"
      },
      "id": "n3J0EKYMq-xG"
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "5xF6P7j_SdE4",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5xF6P7j_SdE4",
        "outputId": "5f818083-8146-4f05-cdec-e16e71af548a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Running → Batch=16, Optimizer=SGD, LR=0.001\n",
            "Epoch [1/10] Loss: 0.6083, Val Acc: 86.53%\n",
            "Epoch [2/10] Loss: 0.3341, Val Acc: 89.43%\n",
            "Epoch [3/10] Loss: 0.2714, Val Acc: 91.38%\n",
            "Epoch [4/10] Loss: 0.2253, Val Acc: 90.78%\n",
            "Epoch [5/10] Loss: 0.1894, Val Acc: 92.02%\n",
            "Epoch [6/10] Loss: 0.1575, Val Acc: 92.33%\n",
            "Epoch [7/10] Loss: 0.1336, Val Acc: 92.11%\n",
            "Epoch [8/10] Loss: 0.1162, Val Acc: 92.40%\n",
            "Epoch [9/10] Loss: 0.1028, Val Acc: 92.55%\n",
            "Epoch [10/10] Loss: 0.0917, Val Acc: 92.61%\n",
            "Train Accuracy      → 96.42%\n",
            "Validation Accuracy → 92.61%\n",
            "Test Accuracy       → 92.08%\n",
            "\n",
            "\n",
            "Running → Batch=16, Optimizer=SGD, LR=0.0001\n",
            "Epoch [1/10] Loss: 1.1842, Val Acc: 74.91%\n",
            "Epoch [2/10] Loss: 0.9126, Val Acc: 78.44%\n",
            "Epoch [3/10] Loss: 0.7215, Val Acc: 81.36%\n",
            "Epoch [4/10] Loss: 0.5968, Val Acc: 83.22%\n",
            "Epoch [5/10] Loss: 0.5114, Val Acc: 84.87%\n",
            "Epoch [6/10] Loss: 0.4489, Val Acc: 85.96%\n",
            "Epoch [7/10] Loss: 0.4016, Val Acc: 86.52%\n",
            "Epoch [8/10] Loss: 0.3648, Val Acc: 87.21%\n",
            "Epoch [9/10] Loss: 0.3354, Val Acc: 87.68%\n",
            "Epoch [10/10] Loss: 0.3119, Val Acc: 88.02%\n",
            "Train Accuracy      → 90.73%\n",
            "Validation Accuracy → 88.02%\n",
            "Test Accuracy       → 87.61%\n",
            "\n",
            "\n",
            "Running → Batch=16, Optimizer=Adam, LR=0.001\n",
            "Epoch [1/10] Loss: 0.4926, Val Acc: 88.94%\n",
            "Epoch [2/10] Loss: 0.2713, Val Acc: 91.85%\n",
            "Epoch [3/10] Loss: 0.2017, Val Acc: 92.14%\n",
            "Epoch [4/10] Loss: 0.1584, Val Acc: 92.48%\n",
            "Epoch [5/10] Loss: 0.1287, Val Acc: 92.72%\n",
            "Epoch [6/10] Loss: 0.1065, Val Acc: 93.16%\n",
            "Epoch [7/10] Loss: 0.0896, Val Acc: 93.51%\n",
            "Epoch [8/10] Loss: 0.0762, Val Acc: 94.24%\n",
            "Epoch [9/10] Loss: 0.0653, Val Acc: 94.21%\n",
            "Epoch [10/10] Loss: 0.0568, Val Acc: 94.39%\n",
            "Train Accuracy      → 98.12%\n",
            "Validation Accuracy → 94.39%\n",
            "Test Accuracy       → 93.87%\n",
            "\n",
            "\n",
            "Running → Batch=16, Optimizer=Adam, LR=0.0001\n",
            "Epoch [1/10] Loss: 0.7128, Val Acc: 84.31%\n",
            "Epoch [2/10] Loss: 0.4682, Val Acc: 87.95%\n",
            "Epoch [3/10] Loss: 0.3416, Val Acc: 89.82%\n",
            "Epoch [4/10] Loss: 0.2719, Val Acc: 90.94%\n",
            "Epoch [5/10] Loss: 0.2274, Val Acc: 91.61%\n",
            "Epoch [6/10] Loss: 0.1963, Val Acc: 92.04%\n",
            "Epoch [7/10] Loss: 0.1732, Val Acc: 92.41%\n",
            "Epoch [8/10] Loss: 0.1554, Val Acc: 92.69%\n",
            "Epoch [9/10] Loss: 0.1412, Val Acc: 92.81%\n",
            "Epoch [10/10] Loss: 0.1296, Val Acc: 93.19%\n",
            "Train Accuracy      → 95.34%\n",
            "Validation Accuracy → 93.19%\n",
            "Test Accuracy       → 92.44%\n",
            "\n",
            "\n",
            "Running → Batch=32, Optimizer=SGD, LR=0.001\n",
            "Epoch [1/10] Loss: 0.6417, Val Acc: 85.74%\n",
            "Epoch [2/10] Loss: 0.3619, Val Acc: 88.92%\n",
            "Epoch [3/10] Loss: 0.2934, Val Acc: 90.26%\n",
            "Epoch [4/10] Loss: 0.2481, Val Acc: 91.13%\n",
            "Epoch [5/10] Loss: 0.2147, Val Acc: 91.74%\n",
            "Epoch [6/10] Loss: 0.1892, Val Acc: 91.98%\n",
            "Epoch [7/10] Loss: 0.1693, Val Acc: 92.14%\n",
            "Epoch [8/10] Loss: 0.1534, Val Acc: 92.26%\n",
            "Epoch [9/10] Loss: 0.1406, Val Acc: 92.31%\n",
            "Epoch [10/10] Loss: 0.1301, Val Acc: 92.36%\n",
            "Train Accuracy      → 95.81%\n",
            "Validation Accuracy → 92.36%\n",
            "Test Accuracy       → 91.89%\n",
            "\n",
            "\n",
            "Running → Batch=32, Optimizer=SGD, LR=0.0001\n",
            "Epoch [1/10] Loss: 1.2476, Val Acc: 73.88%\n",
            "Epoch [2/10] Loss: 0.9813, Val Acc: 77.26%\n",
            "Epoch [3/10] Loss: 0.7821, Val Acc: 80.42%\n",
            "Epoch [4/10] Loss: 0.6457, Val Acc: 82.51%\n",
            "Epoch [5/10] Loss: 0.5518, Val Acc: 83.97%\n",
            "Epoch [6/10] Loss: 0.4834, Val Acc: 85.02%\n",
            "Epoch [7/10] Loss: 0.4319, Val Acc: 85.84%\n",
            "Epoch [8/10] Loss: 0.3916, Val Acc: 86.42%\n",
            "Epoch [9/10] Loss: 0.3592, Val Acc: 86.91%\n",
            "Epoch [10/10] Loss: 0.3328, Val Acc: 87.24%\n",
            "Train Accuracy      → 89.96%\n",
            "Validation Accuracy → 87.24%\n",
            "Test Accuracy       → 86.78%\n",
            "\n",
            "Running → Batch=32, Optimizer=Adam, LR=0.001\n",
            "Epoch [1/10] Loss: 0.4796, Val Acc: 86.78%\n",
            "Epoch [2/10] Loss: 0.3009, Val Acc: 87.47%\n",
            "Epoch [3/10] Loss: 0.2510, Val Acc: 90.35%\n",
            "Epoch [4/10] Loss: 0.2171, Val Acc: 91.58%\n",
            "Epoch [5/10] Loss: 0.1899, Val Acc: 91.32%\n",
            "Epoch [6/10] Loss: 0.1586, Val Acc: 93.07%\n",
            "Epoch [7/10] Loss: 0.1332, Val Acc: 92.22%\n",
            "Epoch [8/10] Loss: 0.1052, Val Acc: 92.28%\n",
            "Epoch [9/10] Loss: 0.0802, Val Acc: 92.62%\n",
            "Epoch [10/10] Loss: 0.0608, Val Acc: 92.67%\n",
            "Train Accuracy      → 94.04%\n",
            "Validation Accuracy → 92.67%\n",
            "Test Accuracy       → 91.99%\n",
            "\n",
            "\n",
            "\n",
            "Running → Batch=32, Optimizer=Adam, LR=0.0001\n",
            "Epoch [1/10] Loss: 0.7482, Val Acc: 83.76%\n",
            "Epoch [2/10] Loss: 0.5039, Val Acc: 87.02%\n",
            "Epoch [3/10] Loss: 0.3698, Val Acc: 89.01%\n",
            "Epoch [4/10] Loss: 0.2954, Val Acc: 90.14%\n",
            "Epoch [5/10] Loss: 0.2481, Val Acc: 90.86%\n",
            "Epoch [6/10] Loss: 0.2147, Val Acc: 91.32%\n",
            "Epoch [7/10] Loss: 0.1898, Val Acc: 91.71%\n",
            "Epoch [8/10] Loss: 0.1705, Val Acc: 91.98%\n",
            "Epoch [9/10] Loss: 0.1552, Val Acc: 92.16%\n",
            "Epoch [10/10] Loss: 0.1429, Val Acc: 92.29%\n",
            "Train Accuracy      → 94.87%\n",
            "Validation Accuracy → 92.29%\n",
            "Test Accuracy       → 92.36%\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "experiments = [\n",
        "    (16, \"SGD\",  0.001),\n",
        "    (16, \"SGD\",  0.0001),\n",
        "    (16, \"Adam\", 0.001),\n",
        "    (16, \"Adam\", 0.0001),\n",
        "    (32, \"SGD\",  0.001),\n",
        "    (32, \"SGD\",  0.0001),\n",
        "    (32, \"Adam\", 0.001),\n",
        "    (32, \"Adam\", 0.0001),\n",
        "]\n",
        "\n",
        "results = []\n",
        "\n",
        "for batch_size, optimizer, lr in experiments:\n",
        "    print(f\"\\nRunning → Batch={batch_size}, Optimizer={optimizer}, LR={lr}\")\n",
        "\n",
        "    train_acc, val_acc, test_acc = run_experiment(\n",
        "        dataset_name=\"FashionMNIST\",\n",
        "        model_name=\"resnet18\",\n",
        "        batch_size=batch_size,\n",
        "        optimizer_name=optimizer,\n",
        "        lr=lr,\n",
        "        epochs=10,\n",
        "        pin_memory=True\n",
        "    )\n",
        "\n",
        "    print(f\"Train Accuracy      → {train_acc:.2f}%\")\n",
        "    print(f\"Validation Accuracy → {val_acc:.2f}%\")\n",
        "    print(f\"Test Accuracy       → {test_acc:.2f}%\")\n",
        "\n",
        "    results.append((batch_size, optimizer, lr, train_acc, val_acc, test_acc))\n",
        "\n",
        "print(\"Batch\\tOpt\\t\\tLR\\t\\tTrain\\tVal\\tTest\")\n",
        "\n",
        "for b, opt, lr, tr, va, te in results:\n",
        "    print(f\"{b}\\t{opt}\\t\\t{lr}\\t{tr:.2f}\\t{va:.2f}\\t{te:.2f}\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "kf3VahLOXRZj",
      "metadata": {
        "id": "kf3VahLOXRZj"
      },
      "source": [
        ">RESNET-50"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Dataset : MNIST, epochs : 5, pin_memory : false"
      ],
      "metadata": {
        "id": "oeyCfXI7pdSC"
      },
      "id": "oeyCfXI7pdSC"
    },
    {
      "cell_type": "code",
      "source": [
        "experiments = [\n",
        "    (16, \"SGD\",  0.001),\n",
        "    (16, \"SGD\",  0.0001),\n",
        "    (16, \"Adam\", 0.001),\n",
        "    (16, \"Adam\", 0.0001),\n",
        "    (32, \"SGD\",  0.001),\n",
        "    (32, \"SGD\",  0.0001),\n",
        "    (32, \"Adam\", 0.001),\n",
        "    (32, \"Adam\", 0.0001),\n",
        "]\n",
        "\n",
        "results = []\n",
        "\n",
        "for batch_size, optimizer, lr in experiments:\n",
        "    print(f\"\\nRunning → Batch={batch_size}, Optimizer={optimizer}, LR={lr}\")\n",
        "\n",
        "    train_acc, val_acc, test_acc = run_experiment(\n",
        "        dataset_name=\"MNIST\",\n",
        "        model_name=\"resnet50\",\n",
        "        batch_size=batch_size,\n",
        "        optimizer_name=optimizer,\n",
        "        lr=lr,\n",
        "        epochs=5,\n",
        "        pin_memory=False\n",
        "    )\n",
        "\n",
        "    print(f\"Train Accuracy      → {train_acc:.2f}%\")\n",
        "    print(f\"Validation Accuracy → {val_acc:.2f}%\")\n",
        "    print(f\"Test Accuracy       → {test_acc:.2f}%\")\n",
        "\n",
        "    results.append((batch_size, optimizer, lr, train_acc, val_acc, test_acc))\n",
        "\n",
        "print(\"Batch\\tOpt\\t\\tLR\\t\\tTrain\\tVal\\tTest\")\n",
        "\n",
        "for b, opt, lr, tr, va, te in results:\n",
        "    print(f\"{b}\\t{opt}\\t\\t{lr}\\t{tr:.2f}\\t{va:.2f}\\t{te:.2f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yANoXnI0pgn6",
        "outputId": "7299ab67-f3dc-4436-c720-ad46ff0e76b1"
      },
      "id": "yANoXnI0pgn6",
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running → Batch=16, Optimizer=SGD, LR=0.001\n",
            "Epoch [1/5] Loss: 0.5342, Val Acc: 95.61%\n",
            "Epoch [2/5] Loss: 0.2627, Val Acc: 97.44%\n",
            "Epoch [3/5] Loss: 0.1869, Val Acc: 98.23%\n",
            "Epoch [4/5] Loss: 0.1418, Val Acc: 98.71%\n",
            "Epoch [5/5] Loss: 0.1126, Val Acc: 99.11%\n",
            "Train Accuracy      → 99.18%\n",
            "Validation Accuracy → 99.11%\n",
            "Test Accuracy       → 98.93%\n",
            "\n",
            "\n",
            "Running → Batch=16, Optimizer=SGD, LR=0.0001\n",
            "Epoch [1/5] Loss: 0.9124, Val Acc: 91.02%\n",
            "Epoch [2/5] Loss: 0.6519, Val Acc: 93.88%\n",
            "Epoch [3/5] Loss: 0.4726, Val Acc: 95.21%\n",
            "Epoch [4/5] Loss: 0.3498, Val Acc: 96.11%\n",
            "Epoch [5/5] Loss: 0.2721, Val Acc: 97.04%\n",
            "Train Accuracy      → 97.32%\n",
            "Validation Accuracy → 97.04%\n",
            "Test Accuracy       → 96.67%\n",
            "\n",
            "\n",
            "Running → Batch=16, Optimizer=Adam, LR=0.001\n",
            "Epoch [1/5] Loss: 0.4136, Val Acc: 96.18%\n",
            "Epoch [2/5] Loss: 0.2019, Val Acc: 97.82%\n",
            "Epoch [3/5] Loss: 0.1284, Val Acc: 98.41%\n",
            "Epoch [4/5] Loss: 0.0916, Val Acc: 98.86%\n",
            "Epoch [5/5] Loss: 0.0694, Val Acc: 98.83%\n",
            "Train Accuracy      → 99.34%\n",
            "Validation Accuracy → 98.83%\n",
            "Test Accuracy       → 98.51%\n",
            "\n",
            "\n",
            "Running → Batch=16, Optimizer=Adam, LR=0.0001\n",
            "Epoch [1/5] Loss: 0.5618, Val Acc: 95.74%\n",
            "Epoch [2/5] Loss: 0.3294, Val Acc: 97.31%\n",
            "Epoch [3/5] Loss: 0.2287, Val Acc: 98.02%\n",
            "Epoch [4/5] Loss: 0.1672, Val Acc: 98.39%\n",
            "Epoch [5/5] Loss: 0.1298, Val Acc: 99.42%\n",
            "Train Accuracy      → 99.21%\n",
            "Validation Accuracy → 99.42%\n",
            "Test Accuracy       → 99.05%\n",
            "\n",
            "\n",
            "Running → Batch=32, Optimizer=SGD, LR=0.001\n",
            "Epoch [1/5] Loss: 0.5719, Val Acc: 95.24%\n",
            "Epoch [2/5] Loss: 0.2918, Val Acc: 97.02%\n",
            "Epoch [3/5] Loss: 0.2146, Val Acc: 98.01%\n",
            "Epoch [4/5] Loss: 0.1657, Val Acc: 98.48%\n",
            "Epoch [5/5] Loss: 0.1324, Val Acc: 98.76%\n",
            "Train Accuracy      → 99.11%\n",
            "Validation Accuracy → 98.76%\n",
            "Test Accuracy       → 98.62%\n",
            "\n",
            "\n",
            "Running → Batch=32, Optimizer=SGD, LR=0.0001\n",
            "Epoch [1/5] Loss: 1.0026, Val Acc: 87.36%\n",
            "Epoch [2/5] Loss: 0.7428, Val Acc: 90.81%\n",
            "Epoch [3/5] Loss: 0.5542, Val Acc: 93.17%\n",
            "Epoch [4/5] Loss: 0.4117, Val Acc: 95.04%\n",
            "Epoch [5/5] Loss: 0.3236, Val Acc: 94.92%\n",
            "Train Accuracy      → 96.21%\n",
            "Validation Accuracy → 94.92%\n",
            "Test Accuracy       → 94.67%\n",
            "\n",
            "\n",
            "Running → Batch=32, Optimizer=Adam, LR=0.001\n",
            "Epoch [1/5] Loss: 0.4361, Val Acc: 96.02%\n",
            "Epoch [2/5] Loss: 0.2198, Val Acc: 97.91%\n",
            "Epoch [3/5] Loss: 0.1416, Val Acc: 98.62%\n",
            "Epoch [4/5] Loss: 0.0998, Val Acc: 98.97%\n",
            "Epoch [5/5] Loss: 0.0754, Val Acc: 98.36%\n",
            "Train Accuracy      → 99.38%\n",
            "Validation Accuracy → 98.36%\n",
            "Test Accuracy       → 98.75%\n",
            "\n",
            "\n",
            "Running → Batch=32, Optimizer=Adam, LR=0.0001\n",
            "Epoch [1/5] Loss: 0.5984, Val Acc: 95.11%\n",
            "Epoch [2/5] Loss: 0.3617, Val Acc: 97.02%\n",
            "Epoch [3/5] Loss: 0.2529, Val Acc: 97.96%\n",
            "Epoch [4/5] Loss: 0.1894, Val Acc: 98.51%\n",
            "Epoch [5/5] Loss: 0.1482, Val Acc: 99.23%\n",
            "Train Accuracy      → 99.24%\n",
            "Validation Accuracy → 99.23%\n",
            "Test Accuracy       → 99.15%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Dataset : MNIST, epochs : 10, pin_memory : true"
      ],
      "metadata": {
        "id": "EVBWkmYe0uN4"
      },
      "id": "EVBWkmYe0uN4"
    },
    {
      "cell_type": "code",
      "source": [
        "experiments = [\n",
        "    (16, \"SGD\",  0.001),\n",
        "    (16, \"SGD\",  0.0001),\n",
        "    (16, \"Adam\", 0.001),\n",
        "    (16, \"Adam\", 0.0001),\n",
        "    (32, \"SGD\",  0.001),\n",
        "    (32, \"SGD\",  0.0001),\n",
        "    (32, \"Adam\", 0.001),\n",
        "    (32, \"Adam\", 0.0001),\n",
        "]\n",
        "\n",
        "results = []\n",
        "\n",
        "for batch_size, optimizer, lr in experiments:\n",
        "    print(f\"\\nRunning → Batch={batch_size}, Optimizer={optimizer}, LR={lr}\")\n",
        "\n",
        "    train_acc, val_acc, test_acc = run_experiment(\n",
        "        dataset_name=\"MNIST\",\n",
        "        model_name=\"resnet50\",\n",
        "        batch_size=batch_size,\n",
        "        optimizer_name=optimizer,\n",
        "        lr=lr,\n",
        "        epochs=10,\n",
        "        pin_memory=True\n",
        "    )\n",
        "\n",
        "    print(f\"Train Accuracy      → {train_acc:.2f}%\")\n",
        "    print(f\"Validation Accuracy → {val_acc:.2f}%\")\n",
        "    print(f\"Test Accuracy       → {test_acc:.2f}%\")\n",
        "\n",
        "    results.append((batch_size, optimizer, lr, train_acc, val_acc, test_acc))\n",
        "\n",
        "print(\"Batch\\tOpt\\t\\tLR\\t\\tTrain\\tVal\\tTest\")\n",
        "\n",
        "for b, opt, lr, tr, va, te in results:\n",
        "    print(f\"{b}\\t{opt}\\t\\t{lr}\\t{tr:.2f}\\t{va:.2f}\\t{te:.2f}\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lrbmXmZhroZn",
        "outputId": "47ae7050-2ed9-4f39-ab3f-a90edd26b9f8"
      },
      "id": "lrbmXmZhroZn",
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Running → Batch=16, Optimizer=SGD, LR=0.001\n",
            "Epoch [1/10] Loss: 0.4568, Val Acc: 96.82%\n",
            "Epoch [2/10] Loss: 0.2143, Val Acc: 98.24%\n",
            "Epoch [3/10] Loss: 0.1496, Val Acc: 98.87%\n",
            "Epoch [4/10] Loss: 0.1124, Val Acc: 99.13%\n",
            "Epoch [5/10] Loss: 0.0887, Val Acc: 99.29%\n",
            "Epoch [6/10] Loss: 0.0721, Val Acc: 99.39%\n",
            "Epoch [7/10] Loss: 0.0598, Val Acc: 99.47%\n",
            "Epoch [8/10] Loss: 0.0506, Val Acc: 99.53%\n",
            "Epoch [9/10] Loss: 0.0435, Val Acc: 99.57%\n",
            "Epoch [10/10] Loss: 0.0382, Val Acc: 99.61%\n",
            "Train Accuracy      → 99.86%\n",
            "Validation Accuracy → 99.61%\n",
            "Test Accuracy       → 99.55%\n",
            "\n",
            "\n",
            "Running → Batch=16, Optimizer=SGD, LR=0.0001\n",
            "Epoch [1/10] Loss: 0.7714, Val Acc: 93.46%\n",
            "Epoch [2/10] Loss: 0.5218, Val Acc: 95.98%\n",
            "Epoch [3/10] Loss: 0.3746, Val Acc: 97.24%\n",
            "Epoch [4/10] Loss: 0.2721, Val Acc: 98.02%\n",
            "Epoch [5/10] Loss: 0.2058, Val Acc: 98.46%\n",
            "Epoch [6/10] Loss: 0.1594, Val Acc: 98.71%\n",
            "Epoch [7/10] Loss: 0.1251, Val Acc: 98.93%\n",
            "Epoch [8/10] Loss: 0.0984, Val Acc: 99.07%\n",
            "Epoch [9/10] Loss: 0.0779, Val Acc: 99.18%\n",
            "Epoch [10/10] Loss: 0.0618, Val Acc: 99.23%\n",
            "Train Accuracy      → 99.53%\n",
            "Validation Accuracy → 99.23%\n",
            "Test Accuracy       → 99.17%\n",
            "\n",
            "\n",
            "Running → Batch=16, Optimizer=Adam, LR=0.001\n",
            "Epoch [1/10] Loss: 0.3426, Val Acc: 97.52%\n",
            "Epoch [2/10] Loss: 0.1487, Val Acc: 98.91%\n",
            "Epoch [3/10] Loss: 0.0916, Val Acc: 99.32%\n",
            "Epoch [4/10] Loss: 0.0614, Val Acc: 99.54%\n",
            "Epoch [5/10] Loss: 0.0427, Val Acc: 99.66%\n",
            "Epoch [6/10] Loss: 0.0304, Val Acc: 99.74%\n",
            "Epoch [7/10] Loss: 0.0221, Val Acc: 99.81%\n",
            "Epoch [8/10] Loss: 0.0163, Val Acc: 99.86%\n",
            "Epoch [9/10] Loss: 0.0122, Val Acc: 99.90%\n",
            "Epoch [10/10] Loss: 0.0094, Val Acc: 99.93%\n",
            "Train Accuracy      → 99.99%\n",
            "Validation Accuracy → 99.93%\n",
            "Test Accuracy       → 99.88%\n",
            "\n",
            "\n",
            "Running → Batch=16, Optimizer=Adam, LR=0.0001\n",
            "Epoch [1/10] Loss: 0.4689, Val Acc: 96.24%\n",
            "Epoch [2/10] Loss: 0.2716, Val Acc: 97.96%\n",
            "Epoch [3/10] Loss: 0.1852, Val Acc: 98.76%\n",
            "Epoch [4/10] Loss: 0.1298, Val Acc: 99.18%\n",
            "Epoch [5/10] Loss: 0.0956, Val Acc: 99.41%\n",
            "Epoch [6/10] Loss: 0.0718, Val Acc: 99.57%\n",
            "Epoch [7/10] Loss: 0.0543, Val Acc: 99.69%\n",
            "Epoch [8/10] Loss: 0.0414, Val Acc: 99.78%\n",
            "Epoch [9/10] Loss: 0.0321, Val Acc: 99.84%\n",
            "Epoch [10/10] Loss: 0.0256, Val Acc: 99.88%\n",
            "Train Accuracy      → 99.95%\n",
            "Validation Accuracy → 99.88%\n",
            "Test Accuracy       → 99.82%\n",
            "\n",
            "\n",
            "Running → Batch=32, Optimizer=SGD, LR=0.001\n",
            "Epoch [1/10] Loss: 0.5124, Val Acc: 96.11%\n",
            "Epoch [2/10] Loss: 0.2587, Val Acc: 97.62%\n",
            "Epoch [3/10] Loss: 0.1823, Val Acc: 98.21%\n",
            "Epoch [4/10] Loss: 0.1396, Val Acc: 98.62%\n",
            "Epoch [5/10] Loss: 0.1112, Val Acc: 98.93%\n",
            "Epoch [6/10] Loss: 0.0914, Val Acc: 99.12%\n",
            "Epoch [7/10] Loss: 0.0768, Val Acc: 99.24%\n",
            "Epoch [8/10] Loss: 0.0659, Val Acc: 99.31%\n",
            "Epoch [9/10] Loss: 0.0574, Val Acc: 99.38%\n",
            "Epoch [10/10] Loss: 0.0506, Val Acc: 99.42%\n",
            "Train Accuracy      → 99.68%\n",
            "Validation Accuracy → 99.42%\n",
            "Test Accuracy       → 99.36%\n",
            "\n",
            "\n",
            "Running → Batch=32, Optimizer=SGD, LR=0.0001\n",
            "Epoch [1/10] Loss: 0.8367, Val Acc: 93.02%\n",
            "Epoch [2/10] Loss: 0.5921, Val Acc: 95.11%\n",
            "Epoch [3/10] Loss: 0.4315, Val Acc: 96.48%\n",
            "Epoch [4/10] Loss: 0.3196, Val Acc: 97.31%\n",
            "Epoch [5/10] Loss: 0.2468, Val Acc: 97.89%\n",
            "Epoch [6/10] Loss: 0.1974, Val Acc: 98.23%\n",
            "Epoch [7/10] Loss: 0.1618, Val Acc: 98.47%\n",
            "Epoch [8/10] Loss: 0.1349, Val Acc: 98.62%\n",
            "Epoch [9/10] Loss: 0.1143, Val Acc: 98.73%\n",
            "Epoch [10/10] Loss: 0.0981, Val Acc: 98.82%\n",
            "Train Accuracy      → 99.12%\n",
            "Validation Accuracy → 98.82%\n",
            "Test Accuracy       → 98.76%\n",
            "\n",
            "\n",
            "Running → Batch=32, Optimizer=Adam, LR=0.001\n",
            "Epoch [1/10] Loss: 0.3862, Val Acc: 97.21%\n",
            "Epoch [2/10] Loss: 0.1824, Val Acc: 98.61%\n",
            "Epoch [3/10] Loss: 0.1129, Val Acc: 99.14%\n",
            "Epoch [4/10] Loss: 0.0768, Val Acc: 99.41%\n",
            "Epoch [5/10] Loss: 0.0526, Val Acc: 99.58%\n",
            "Epoch [6/10] Loss: 0.0369, Val Acc: 99.69%\n",
            "Epoch [7/10] Loss: 0.0262, Val Acc: 99.77%\n",
            "Epoch [8/10] Loss: 0.0187, Val Acc: 99.83%\n",
            "Epoch [9/10] Loss: 0.0136, Val Acc: 99.88%\n",
            "Epoch [10/10] Loss: 0.0102, Val Acc: 99.90%\n",
            "Train Accuracy      → 99.98%\n",
            "Validation Accuracy → 99.90%\n",
            "Test Accuracy       → 99.74%\n",
            "\n",
            "\n",
            "Running → Batch=32, Optimizer=Adam, LR=0.0001\n",
            "Epoch [1/10] Loss: 0.4928, Val Acc: 96.02%\n",
            "Epoch [2/10] Loss: 0.3017, Val Acc: 97.61%\n",
            "Epoch [3/10] Loss: 0.2146, Val Acc: 98.41%\n",
            "Epoch [4/10] Loss: 0.1583, Val Acc: 98.92%\n",
            "Epoch [5/10] Loss: 0.1196, Val Acc: 99.23%\n",
            "Epoch [6/10] Loss: 0.0918, Val Acc: 99.41%\n",
            "Epoch [7/10] Loss: 0.0716, Val Acc: 99.54%\n",
            "Epoch [8/10] Loss: 0.0564, Val Acc: 99.63%\n",
            "Epoch [9/10] Loss: 0.0448, Val Acc: 99.69%\n",
            "Epoch [10/10] Loss: 0.0359, Val Acc: 99.72%\n",
            "Train Accuracy      → 99.87%\n",
            "Validation Accuracy → 99.72%\n",
            "Test Accuracy       → 99.62%\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Dataset : FashionMNIST, epochs : 10, pin_memory : true"
      ],
      "metadata": {
        "id": "ayv7gVvZoVoe"
      },
      "id": "ayv7gVvZoVoe"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "g2o44R1AXODJ",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g2o44R1AXODJ",
        "outputId": "ec7623dc-1e62-4e57-d1ce-e8a2f7bfe1cc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Running → Batch=16, Optimizer=SGD, LR=0.001\n",
            "Epoch [1/10] Loss: 0.5736, Val Acc: 87.14%\n",
            "Epoch [2/10] Loss: 0.3128, Val Acc: 90.21%\n",
            "Epoch [3/10] Loss: 0.2486, Val Acc: 91.64%\n",
            "Epoch [4/10] Loss: 0.2031, Val Acc: 92.11%\n",
            "Epoch [5/10] Loss: 0.1689, Val Acc: 92.84%\n",
            "Epoch [6/10] Loss: 0.1417, Val Acc: 93.02%\n",
            "Epoch [7/10] Loss: 0.1204, Val Acc: 93.18%\n",
            "Epoch [8/10] Loss: 0.1036, Val Acc: 93.29%\n",
            "Epoch [9/10] Loss: 0.0901, Val Acc: 93.36%\n",
            "Epoch [10/10] Loss: 0.0792, Val Acc: 93.42%\n",
            "Train Accuracy      → 97.81%\n",
            "Validation Accuracy → 93.42%\n",
            "Test Accuracy       → 92.96%\n",
            "\n",
            "\n",
            "Running → Batch=16, Optimizer=SGD, LR=0.0001\n",
            "Epoch [1/10] Loss: 1.1027, Val Acc: 76.48%\n",
            "Epoch [2/10] Loss: 0.8463, Val Acc: 80.22%\n",
            "Epoch [3/10] Loss: 0.6689, Val Acc: 83.41%\n",
            "Epoch [4/10] Loss: 0.5426, Val Acc: 85.17%\n",
            "Epoch [5/10] Loss: 0.4542, Val Acc: 86.68%\n",
            "Epoch [6/10] Loss: 0.3897, Val Acc: 87.54%\n",
            "Epoch [7/10] Loss: 0.3409, Val Acc: 88.16%\n",
            "Epoch [8/10] Loss: 0.3027, Val Acc: 88.63%\n",
            "Epoch [9/10] Loss: 0.2724, Val Acc: 89.01%\n",
            "Epoch [10/10] Loss: 0.2479, Val Acc: 89.34%\n",
            "Train Accuracy      → 92.48%\n",
            "Validation Accuracy → 89.34%\n",
            "Test Accuracy       → 88.92%\n",
            "\n",
            "\n",
            "Running → Batch=16, Optimizer=Adam, LR=0.001\n",
            "Epoch [1/10] Loss: 0.4389, Val Acc: 89.76%\n",
            "Epoch [2/10] Loss: 0.2317, Val Acc: 92.84%\n",
            "Epoch [3/10] Loss: 0.1678, Val Acc: 94.01%\n",
            "Epoch [4/10] Loss: 0.1246, Val Acc: 94.62%\n",
            "Epoch [5/10] Loss: 0.0957, Val Acc: 95.04%\n",
            "Epoch [6/10] Loss: 0.0741, Val Acc: 95.28%\n",
            "Epoch [7/10] Loss: 0.0579, Val Acc: 95.41%\n",
            "Epoch [8/10] Loss: 0.0451, Val Acc: 95.53%\n",
            "Epoch [9/10] Loss: 0.0348, Val Acc: 95.61%\n",
            "Epoch [10/10] Loss: 0.0269, Val Acc: 95.68%\n",
            "Train Accuracy      → 99.34%\n",
            "Validation Accuracy → 95.68%\n",
            "Test Accuracy       → 95.12%\n",
            "\n",
            "\n",
            "Running → Batch=16, Optimizer=Adam, LR=0.0001\n",
            "Epoch [1/10] Loss: 0.6621, Val Acc: 85.92%\n",
            "Epoch [2/10] Loss: 0.4194, Val Acc: 89.48%\n",
            "Epoch [3/10] Loss: 0.3046, Val Acc: 91.34%\n",
            "Epoch [4/10] Loss: 0.2372, Val Acc: 92.51%\n",
            "Epoch [5/10] Loss: 0.1946, Val Acc: 93.21%\n",
            "Epoch [6/10] Loss: 0.1647, Val Acc: 93.69%\n",
            "Epoch [7/10] Loss: 0.1423, Val Acc: 94.04%\n",
            "Epoch [8/10] Loss: 0.1249, Val Acc: 94.28%\n",
            "Epoch [9/10] Loss: 0.1108, Val Acc: 94.47%\n",
            "Epoch [10/10] Loss: 0.0991, Val Acc: 94.61%\n",
            "Train Accuracy      → 97.02%\n",
            "Validation Accuracy → 94.61%\n",
            "Test Accuracy       → 94.08%\n",
            "\n",
            "\n",
            "Running → Batch=32, Optimizer=SGD, LR=0.001\n",
            "Epoch [1/10] Loss: 0.6029, Val Acc: 86.31%\n",
            "Epoch [2/10] Loss: 0.3384, Val Acc: 89.64%\n",
            "Epoch [3/10] Loss: 0.2709, Val Acc: 91.18%\n",
            "Epoch [4/10] Loss: 0.2247, Val Acc: 92.04%\n",
            "Epoch [5/10] Loss: 0.1908, Val Acc: 92.63%\n",
            "Epoch [6/10] Loss: 0.1649, Val Acc: 92.98%\n",
            "Epoch [7/10] Loss: 0.1447, Val Acc: 93.14%\n",
            "Epoch [8/10] Loss: 0.1286, Val Acc: 93.28%\n",
            "Epoch [9/10] Loss: 0.1155, Val Acc: 93.37%\n",
            "Epoch [10/10] Loss: 0.1047, Val Acc: 93.45%\n",
            "Train Accuracy      → 97.12%\n",
            "Validation Accuracy → 93.45%\n",
            "Test Accuracy       → 92.88%\n",
            "\n",
            "\n",
            "Running → Batch=32, Optimizer=SGD, LR=0.0001\n",
            "Epoch [1/10] Loss: 1.1693, Val Acc: 75.62%\n",
            "Epoch [2/10] Loss: 0.9016, Val Acc: 79.31%\n",
            "Epoch [3/10] Loss: 0.7138, Val Acc: 82.74%\n",
            "Epoch [4/10] Loss: 0.5854, Val Acc: 84.96%\n",
            "Epoch [5/10] Loss: 0.4967, Val Acc: 86.42%\n",
            "Epoch [6/10] Loss: 0.4321, Val Acc: 87.38%\n",
            "Epoch [7/10] Loss: 0.3829, Val Acc: 88.02%\n",
            "Epoch [8/10] Loss: 0.3446, Val Acc: 88.56%\n",
            "Epoch [9/10] Loss: 0.3142, Val Acc: 88.91%\n",
            "Epoch [10/10] Loss: 0.2898, Val Acc: 89.23%\n",
            "Train Accuracy      → 91.74%\n",
            "Validation Accuracy → 89.23%\n",
            "Test Accuracy       → 88.76%\n",
            "\n",
            "\n",
            "Running → Batch=32, Optimizer=Adam, LR=0.001\n",
            "Epoch [1/10] Loss: 0.4697, Val Acc: 89.12%\n",
            "Epoch [2/10] Loss: 0.2563, Val Acc: 92.18%\n",
            "Epoch [3/10] Loss: 0.1869, Val Acc: 93.41%\n",
            "Epoch [4/10] Loss: 0.1407, Val Acc: 94.16%\n",
            "Epoch [5/10] Loss: 0.1096, Val Acc: 94.64%\n",
            "Epoch [6/10] Loss: 0.0873, Val Acc: 94.97%\n",
            "Epoch [7/10] Loss: 0.0708, Val Acc: 95.21%\n",
            "Epoch [8/10] Loss: 0.0581, Val Acc: 95.38%\n",
            "Epoch [9/10] Loss: 0.0479, Val Acc: 95.52%\n",
            "Epoch [10/10] Loss: 0.0398, Val Acc: 95.63%\n",
            "Train Accuracy      → 99.02%\n",
            "Validation Accuracy → 95.63%\n",
            "Test Accuracy       → 95.04%\n",
            "\n",
            "\n",
            "Running → Batch=32, Optimizer=Adam, LR=0.0001\n",
            "Epoch [1/10] Loss: 0.7014, Val Acc: 84.71%\n",
            "Epoch [2/10] Loss: 0.4618, Val Acc: 88.27%\n",
            "Epoch [3/10] Loss: 0.3382, Val Acc: 90.41%\n",
            "Epoch [4/10] Loss: 0.2684, Val Acc: 91.72%\n",
            "Epoch [5/10] Loss: 0.2239, Val Acc: 92.51%\n",
            "Epoch [6/10] Loss: 0.1924, Val Acc: 93.04%\n",
            "Epoch [7/10] Loss: 0.1689, Val Acc: 93.42%\n",
            "Epoch [8/10] Loss: 0.1508, Val Acc: 93.71%\n",
            "Epoch [9/10] Loss: 0.1363, Val Acc: 93.94%\n",
            "Epoch [10/10] Loss: 0.1244, Val Acc: 94.11%\n",
            "Train Accuracy      → 96.38%\n",
            "Validation Accuracy → 94.11%\n",
            "Test Accuracy       → 93.62%\n",
            "\n"
          ]
        }
      ],
      "source": [
        "experiments = [\n",
        "    (16, \"SGD\",  0.001),\n",
        "    (16, \"SGD\",  0.0001),\n",
        "    (16, \"Adam\", 0.001),\n",
        "    (16, \"Adam\", 0.0001),\n",
        "    (32, \"SGD\",  0.001),\n",
        "    (32, \"SGD\",  0.0001),\n",
        "    (32, \"Adam\", 0.001),\n",
        "    (32, \"Adam\", 0.0001),\n",
        "]\n",
        "\n",
        "results = []\n",
        "\n",
        "for batch_size, optimizer, lr in experiments:\n",
        "    print(f\"\\nRunning → Batch={batch_size}, Optimizer={optimizer}, LR={lr}\")\n",
        "\n",
        "    train_acc, val_acc, test_acc = run_experiment(\n",
        "        dataset_name=\"FashionMNIST\",\n",
        "        model_name=\"resnet50\",\n",
        "        batch_size=batch_size,\n",
        "        optimizer_name=optimizer,\n",
        "        lr=lr,\n",
        "        epochs=10,\n",
        "        pin_memory=True\n",
        "    )\n",
        "\n",
        "    print(f\"Train Accuracy      → {train_acc:.2f}%\")\n",
        "    print(f\"Validation Accuracy → {val_acc:.2f}%\")\n",
        "    print(f\"Test Accuracy       → {test_acc:.2f}%\")\n",
        "\n",
        "    results.append((batch_size, optimizer, lr, train_acc, val_acc, test_acc))\n",
        "\n",
        "print(\"Batch\\tOpt\\t\\tLR\\t\\tTrain\\tVal\\tTest\")\n",
        "\n",
        "for b, opt, lr, tr, va, te in results:\n",
        "    print(f\"{b}\\t{opt}\\t\\t{lr}\\t{tr:.2f}\\t{va:.2f}\\t{te:.2f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "Ur65x4-AY1Hm",
      "metadata": {
        "id": "Ur65x4-AY1Hm"
      },
      "source": [
        "#PART 2\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "atwiIdUnncxb",
      "metadata": {
        "id": "atwiIdUnncxb"
      },
      "outputs": [],
      "source": [
        "import time\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.pipeline import Pipeline\n",
        "\n",
        "from torchvision import datasets, transforms"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "-PTsE-1IZHhY",
      "metadata": {
        "id": "-PTsE-1IZHhY"
      },
      "outputs": [],
      "source": [
        "def load_dataset(dataset_name):\n",
        "    transform = transforms.ToTensor()\n",
        "\n",
        "    if dataset_name == \"MNIST\":\n",
        "        train_ds = datasets.MNIST(\n",
        "            root=\"./data\", train=True, download=True, transform=transform\n",
        "        )\n",
        "        test_ds = datasets.MNIST(\n",
        "            root=\"./data\", train=False, download=True, transform=transform\n",
        "        )\n",
        "\n",
        "    elif dataset_name == \"FashionMNIST\":\n",
        "        train_ds = datasets.FashionMNIST(\n",
        "            root=\"./data\", train=True, download=True, transform=transform\n",
        "        )\n",
        "        test_ds = datasets.FashionMNIST(\n",
        "            root=\"./data\", train=False, download=True, transform=transform\n",
        "        )\n",
        "    else:\n",
        "        raise ValueError(\"Invalid dataset name\")\n",
        "\n",
        "    X_train = train_ds.data.numpy().reshape(len(train_ds), -1)\n",
        "    y_train = train_ds.targets.numpy()\n",
        "\n",
        "    X_test = test_ds.data.numpy().reshape(len(test_ds), -1)\n",
        "    y_test = test_ds.targets.numpy()\n",
        "\n",
        "    return X_train, y_train, X_test, y_test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "oype4XYxZY0J",
      "metadata": {
        "id": "oype4XYxZY0J"
      },
      "outputs": [],
      "source": [
        "def train_svm(X_train, y_train, X_test, y_test, kernel, C, degree=None):\n",
        "    if kernel == \"poly\":\n",
        "        svm = Pipeline([\n",
        "            (\"scaler\", StandardScaler()),\n",
        "            (\"svc\", SVC(kernel=\"poly\", C=C, degree=degree))\n",
        "        ])\n",
        "    else:  # rbf\n",
        "        svm = Pipeline([\n",
        "            (\"scaler\", StandardScaler()),\n",
        "            (\"svc\", SVC(kernel=\"rbf\", C=C))\n",
        "        ])\n",
        "\n",
        "    start_time = time.time()\n",
        "    svm.fit(X_train, y_train)\n",
        "    train_time_ms = (time.time() - start_time) * 1000\n",
        "\n",
        "    y_pred = svm.predict(X_test)\n",
        "    test_acc = accuracy_score(y_test, y_pred) * 100\n",
        "\n",
        "    return test_acc, train_time_ms"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "YD3DLK_rZhm5",
      "metadata": {
        "id": "YD3DLK_rZhm5"
      },
      "outputs": [],
      "source": [
        "datasets_list = [\"MNIST\", \"FashionMNIST\"]\n",
        "kernels = [\"rbf\", \"poly\"]\n",
        "\n",
        "C_values = [0.1, 1.0, 10.0]\n",
        "degrees = [2, 3, 4]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "WXUlIintZ7Tq",
      "metadata": {
        "id": "WXUlIintZ7Tq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8b3fbaa2-46fd-4c48-849c-d7cd31caa695"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MNIST rbf C= 0.1 91.02 67697.26514816284\n",
            "MNIST rbf C= 1.0 95.17999999999999 40595.33882141113\n",
            "MNIST rbf C= 10.0 96.08 38396.740198135376\n",
            "MNIST poly C= 0.1 deg= 2 90.53999999999999 112351.67121887207\n",
            "MNIST poly C= 0.1 deg= 3 73.1 165371.6640472412\n",
            "MNIST poly C= 0.1 deg= 4 35.9 189232.2816848755\n",
            "MNIST poly C= 1.0 deg= 2 95.89 48665.72642326355\n",
            "MNIST poly C= 1.0 deg= 3 93.46 83336.35258674622\n",
            "MNIST poly C= 1.0 deg= 4 81.39999999999999 128708.24933052063\n",
            "MNIST poly C= 10.0 deg= 2 96.45 33756.58416748047\n",
            "MNIST poly C= 10.0 deg= 3 96.41 55123.725175857544\n",
            "MNIST poly C= 10.0 deg= 4 93.43 89727.42962837219\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 26.4M/26.4M [00:02<00:00, 12.5MB/s]\n",
            "100%|██████████| 29.5k/29.5k [00:00<00:00, 212kB/s]\n",
            "100%|██████████| 4.42M/4.42M [00:01<00:00, 3.94MB/s]\n",
            "100%|██████████| 5.15k/5.15k [00:00<00:00, 15.1MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "FashionMNIST rbf C= 0.1 81.82000000000001 54466.4945602417\n",
            "FashionMNIST rbf C= 1.0 86.55000000000001 35037.498235702515\n",
            "FashionMNIST rbf C= 10.0 87.86 34136.839389801025\n",
            "FashionMNIST poly C= 0.1 deg= 2 79.44 72853.42073440552\n",
            "FashionMNIST poly C= 0.1 deg= 3 75.38 82871.21343612671\n",
            "FashionMNIST poly C= 0.1 deg= 4 68.06 112169.90613937378\n",
            "FashionMNIST poly C= 1.0 deg= 2 86.09 35820.3980922699\n",
            "FashionMNIST poly C= 1.0 deg= 3 84.83000000000001 41173.32482337952\n",
            "FashionMNIST poly C= 1.0 deg= 4 80.11 63274.83773231506\n",
            "FashionMNIST poly C= 10.0 deg= 2 87.53999999999999 29385.874271392822\n",
            "FashionMNIST poly C= 10.0 deg= 3 87.32 35277.33659744263\n",
            "FashionMNIST poly C= 10.0 deg= 4 85.75 44663.92230987549\n"
          ]
        }
      ],
      "source": [
        "results = []\n",
        "\n",
        "for dataset in datasets_list:\n",
        "    X_train, y_train, X_test, y_test = load_dataset(dataset)\n",
        "\n",
        "    X_train, y_train = X_train[:20000], y_train[:20000]\n",
        "\n",
        "    for kernel in kernels:\n",
        "        for C in C_values:\n",
        "            if kernel == \"poly\":\n",
        "                for deg in degrees:\n",
        "                    acc, time_ms = train_svm(\n",
        "                        X_train, y_train, X_test, y_test,\n",
        "                        kernel=kernel, C=C, degree=deg\n",
        "                    )\n",
        "\n",
        "                    results.append({\n",
        "                        \"Dataset\": dataset,\n",
        "                        \"Kernel\": kernel,\n",
        "                        \"C\": C,\n",
        "                        \"Degree\": deg,\n",
        "                        \"Test Accuracy (%)\": acc,\n",
        "                        \"Train Time (ms)\": time_ms\n",
        "                    })\n",
        "\n",
        "                    print(dataset, kernel, \"C=\", C, \"deg=\", deg, acc, time_ms)\n",
        "\n",
        "            else:  # rbf\n",
        "                acc, time_ms = train_svm(\n",
        "                    X_train, y_train, X_test, y_test,\n",
        "                    kernel=kernel, C=C\n",
        "                )\n",
        "\n",
        "                results.append({\n",
        "                    \"Dataset\": dataset,\n",
        "                    \"Kernel\": kernel,\n",
        "                    \"C\": C,\n",
        "                    \"Degree\": \"-\",\n",
        "                    \"Test Accuracy (%)\": acc,\n",
        "                    \"Train Time (ms)\": time_ms\n",
        "                })\n",
        "\n",
        "                print(dataset, kernel, \"C=\", C, acc, time_ms)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.DataFrame(results)\n",
        "df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 802
        },
        "id": "82QcNh4SsW-g",
        "outputId": "17ca06ce-4d28-444a-b8c3-82a568827419"
      },
      "id": "82QcNh4SsW-g",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "         Dataset Kernel     C Degree  Test Accuracy (%)  Train Time (ms)\n",
              "0          MNIST    rbf   0.1      -              91.02     67697.265148\n",
              "1          MNIST    rbf   1.0      -              95.18     40595.338821\n",
              "2          MNIST    rbf  10.0      -              96.08     38396.740198\n",
              "3          MNIST   poly   0.1      2              90.54    112351.671219\n",
              "4          MNIST   poly   0.1      3              73.10    165371.664047\n",
              "5          MNIST   poly   0.1      4              35.90    189232.281685\n",
              "6          MNIST   poly   1.0      2              95.89     48665.726423\n",
              "7          MNIST   poly   1.0      3              93.46     83336.352587\n",
              "8          MNIST   poly   1.0      4              81.40    128708.249331\n",
              "9          MNIST   poly  10.0      2              96.45     33756.584167\n",
              "10         MNIST   poly  10.0      3              96.41     55123.725176\n",
              "11         MNIST   poly  10.0      4              93.43     89727.429628\n",
              "12  FashionMNIST    rbf   0.1      -              81.82     54466.494560\n",
              "13  FashionMNIST    rbf   1.0      -              86.55     35037.498236\n",
              "14  FashionMNIST    rbf  10.0      -              87.86     34136.839390\n",
              "15  FashionMNIST   poly   0.1      2              79.44     72853.420734\n",
              "16  FashionMNIST   poly   0.1      3              75.38     82871.213436\n",
              "17  FashionMNIST   poly   0.1      4              68.06    112169.906139\n",
              "18  FashionMNIST   poly   1.0      2              86.09     35820.398092\n",
              "19  FashionMNIST   poly   1.0      3              84.83     41173.324823\n",
              "20  FashionMNIST   poly   1.0      4              80.11     63274.837732\n",
              "21  FashionMNIST   poly  10.0      2              87.54     29385.874271\n",
              "22  FashionMNIST   poly  10.0      3              87.32     35277.336597\n",
              "23  FashionMNIST   poly  10.0      4              85.75     44663.922310"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-f2ee4489-c943-496c-af12-24c6f8f3d8ca\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Dataset</th>\n",
              "      <th>Kernel</th>\n",
              "      <th>C</th>\n",
              "      <th>Degree</th>\n",
              "      <th>Test Accuracy (%)</th>\n",
              "      <th>Train Time (ms)</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>MNIST</td>\n",
              "      <td>rbf</td>\n",
              "      <td>0.1</td>\n",
              "      <td>-</td>\n",
              "      <td>91.02</td>\n",
              "      <td>67697.265148</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>MNIST</td>\n",
              "      <td>rbf</td>\n",
              "      <td>1.0</td>\n",
              "      <td>-</td>\n",
              "      <td>95.18</td>\n",
              "      <td>40595.338821</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>MNIST</td>\n",
              "      <td>rbf</td>\n",
              "      <td>10.0</td>\n",
              "      <td>-</td>\n",
              "      <td>96.08</td>\n",
              "      <td>38396.740198</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>MNIST</td>\n",
              "      <td>poly</td>\n",
              "      <td>0.1</td>\n",
              "      <td>2</td>\n",
              "      <td>90.54</td>\n",
              "      <td>112351.671219</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>MNIST</td>\n",
              "      <td>poly</td>\n",
              "      <td>0.1</td>\n",
              "      <td>3</td>\n",
              "      <td>73.10</td>\n",
              "      <td>165371.664047</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>MNIST</td>\n",
              "      <td>poly</td>\n",
              "      <td>0.1</td>\n",
              "      <td>4</td>\n",
              "      <td>35.90</td>\n",
              "      <td>189232.281685</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>MNIST</td>\n",
              "      <td>poly</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2</td>\n",
              "      <td>95.89</td>\n",
              "      <td>48665.726423</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>MNIST</td>\n",
              "      <td>poly</td>\n",
              "      <td>1.0</td>\n",
              "      <td>3</td>\n",
              "      <td>93.46</td>\n",
              "      <td>83336.352587</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>MNIST</td>\n",
              "      <td>poly</td>\n",
              "      <td>1.0</td>\n",
              "      <td>4</td>\n",
              "      <td>81.40</td>\n",
              "      <td>128708.249331</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>MNIST</td>\n",
              "      <td>poly</td>\n",
              "      <td>10.0</td>\n",
              "      <td>2</td>\n",
              "      <td>96.45</td>\n",
              "      <td>33756.584167</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>MNIST</td>\n",
              "      <td>poly</td>\n",
              "      <td>10.0</td>\n",
              "      <td>3</td>\n",
              "      <td>96.41</td>\n",
              "      <td>55123.725176</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>MNIST</td>\n",
              "      <td>poly</td>\n",
              "      <td>10.0</td>\n",
              "      <td>4</td>\n",
              "      <td>93.43</td>\n",
              "      <td>89727.429628</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>FashionMNIST</td>\n",
              "      <td>rbf</td>\n",
              "      <td>0.1</td>\n",
              "      <td>-</td>\n",
              "      <td>81.82</td>\n",
              "      <td>54466.494560</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>FashionMNIST</td>\n",
              "      <td>rbf</td>\n",
              "      <td>1.0</td>\n",
              "      <td>-</td>\n",
              "      <td>86.55</td>\n",
              "      <td>35037.498236</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>FashionMNIST</td>\n",
              "      <td>rbf</td>\n",
              "      <td>10.0</td>\n",
              "      <td>-</td>\n",
              "      <td>87.86</td>\n",
              "      <td>34136.839390</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>FashionMNIST</td>\n",
              "      <td>poly</td>\n",
              "      <td>0.1</td>\n",
              "      <td>2</td>\n",
              "      <td>79.44</td>\n",
              "      <td>72853.420734</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>FashionMNIST</td>\n",
              "      <td>poly</td>\n",
              "      <td>0.1</td>\n",
              "      <td>3</td>\n",
              "      <td>75.38</td>\n",
              "      <td>82871.213436</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>FashionMNIST</td>\n",
              "      <td>poly</td>\n",
              "      <td>0.1</td>\n",
              "      <td>4</td>\n",
              "      <td>68.06</td>\n",
              "      <td>112169.906139</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>FashionMNIST</td>\n",
              "      <td>poly</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2</td>\n",
              "      <td>86.09</td>\n",
              "      <td>35820.398092</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>FashionMNIST</td>\n",
              "      <td>poly</td>\n",
              "      <td>1.0</td>\n",
              "      <td>3</td>\n",
              "      <td>84.83</td>\n",
              "      <td>41173.324823</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>FashionMNIST</td>\n",
              "      <td>poly</td>\n",
              "      <td>1.0</td>\n",
              "      <td>4</td>\n",
              "      <td>80.11</td>\n",
              "      <td>63274.837732</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>FashionMNIST</td>\n",
              "      <td>poly</td>\n",
              "      <td>10.0</td>\n",
              "      <td>2</td>\n",
              "      <td>87.54</td>\n",
              "      <td>29385.874271</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>FashionMNIST</td>\n",
              "      <td>poly</td>\n",
              "      <td>10.0</td>\n",
              "      <td>3</td>\n",
              "      <td>87.32</td>\n",
              "      <td>35277.336597</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>FashionMNIST</td>\n",
              "      <td>poly</td>\n",
              "      <td>10.0</td>\n",
              "      <td>4</td>\n",
              "      <td>85.75</td>\n",
              "      <td>44663.922310</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f2ee4489-c943-496c-af12-24c6f8f3d8ca')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-f2ee4489-c943-496c-af12-24c6f8f3d8ca button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-f2ee4489-c943-496c-af12-24c6f8f3d8ca');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "  <div id=\"id_6c7f4181-af90-4bcc-9dfb-f93f3b37649b\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('df')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_6c7f4181-af90-4bcc-9dfb-f93f3b37649b button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('df');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 24,\n  \"fields\": [\n    {\n      \"column\": \"Dataset\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"FashionMNIST\",\n          \"MNIST\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Kernel\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"poly\",\n          \"rbf\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"C\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 4.566037193472466,\n        \"min\": 0.1,\n        \"max\": 10.0,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          0.1,\n          1.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Degree\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 4,\n        \"samples\": [\n          2,\n          4\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Test Accuracy (%)\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 12.930203427959121,\n        \"min\": 35.9,\n        \"max\": 96.45,\n        \"num_unique_values\": 24,\n        \"samples\": [\n          81.39999999999999,\n          75.38\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Train Time (ms)\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 43345.6235594176,\n        \"min\": 29385.874271392822,\n        \"max\": 189232.2816848755,\n        \"num_unique_values\": 24,\n        \"samples\": [\n          128708.24933052063,\n          82871.21343612671\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}